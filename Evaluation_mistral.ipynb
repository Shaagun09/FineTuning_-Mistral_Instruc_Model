{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we are going to run local LLM \"Llama-8B-Instruct\".\n",
        "\n",
        "We will use UnslothAI for this:  https://github.com/unslothai/"
      ],
      "metadata": {
        "id": "UOkGMH4xW2fW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2eSvM9zX_2d3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install unsloth \"xformers==0.0.28.post2\"\n",
        "\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "8c83d243e4d2488989aa7c7994f466b4",
            "d51e36680ee449b88e3fa28a06a8b451",
            "b4a7fa890ef84508b6a2034d0ec8d97d",
            "7d7e4105d01547dab146fc2ec34d4cbb",
            "cbee8c3ee84c497f82886b443fa24907",
            "181012a5b5f6465a80537f6c1b3a6c25",
            "03ad7a12b09845afb6a844864213d7f4",
            "a03fe2db19a34fc3a47092af4e9b9096",
            "be40648fcff241a7afb509470b5037cc",
            "233ba5f201684bd1afcd48b96ffcbd0e",
            "2990151a212141cba52aecddb9eb54a2"
          ]
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "9887c800-a0a0-4ae2-df13-d84adbd66970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2024.12.3: Fast Mistral patching. Transformers:4.46.3.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post2. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c83d243e4d2488989aa7c7994f466b4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 #  5555\n",
        "dtype = None #\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Shaagun/mistral\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    token = \"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\", # You need to get the token from your huggingface account if you want to access Gated models such as Llama-3 from Meta\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Where is our model?\n",
        "device = model.device\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYXX-Rb3V9jn",
        "outputId": "222ed4b2-212c-4a2e-8ae0-828114d1aa85"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_inference(model)# First set the model to the inference mode\n",
        "#  model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL_9kojvWME5",
        "outputId": "63d45bb9-b6a0-4a50-ab10-6dc82e7c026d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MistralForCausalLM(\n",
              "  (model): MistralModel(\n",
              "    (embed_tokens): Embedding(32768, 4096, padding_idx=770)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x MistralDecoderLayer(\n",
              "        (self_attn): MistralAttention(\n",
              "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): MistralMLP(\n",
              "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
              "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\""
      ],
      "metadata": {
        "id": "hS4-e44lVq08"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"Write amazing thing about University of New Haven's students\", # instruction\n",
        "        \"We are called Chargers! and our mascot is Horse\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(device)\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "output = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)\n",
        "response_1 = tokenizer.decode(output[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA0W4vOkViQi",
        "outputId": "81b69269-3a58-4ac0-ed8b-636a3743560e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Write amazing thing about University of New Haven's students\n",
            "\n",
            "### Input:\n",
            "We are called Chargers! and our mascot is Horse\n",
            "\n",
            "### Response:\n",
            "The University of New Haven's students are not only known for their spirit, as represented by their mascot, the Chargers, but they also embody a unique sense of determination and resilience that sets them apart. Just like their fearless mascot, these students charge forward with passion, curiosity, and a relentless pursuit of knowledge. They are a diverse and vibrant community, constantly pushing the boundaries of what is possible and making a significant impact in their respective fields. It's truly amazing to witness the potential and dedication of these Chargers!</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"Santrauka\", # instruction\n",
        "        \"Prašome paaiškinti apie \\\"Shaagun Suresh\\\"\",# input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(device)\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 555)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCxiDCW7Wc47",
        "outputId": "d2fb6f55-e0c0-4fb8-8234-0dfaa07558e1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Santrauka\n",
            "\n",
            "### Input:\n",
            "Prašome paaiškinti apie \"Shaagun Suresh\"\n",
            "\n",
            "### Response:\n",
            "\"Shaagun Suresh yra indijus, jis pradėjo karierą kaip programatorius. Jis turi bachelor's diplomą iš Fakulteto mokslų ir technologijų, o dabar yra vice prezidentas kodėlis 'X'.\"</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"Kiek planetų yra Saulės sistemoje?\", # instruction\n",
        "        \"rumpai atsakyk skaičiais.\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(device)\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "output = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)\n",
        "response_2 = tokenizer.decode(output[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4FWK8nM6H38",
        "outputId": "e799a4e5-874d-4f82-9ba2-99ca440df788"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Kiek planetų yra Saulės sistemoje?\n",
            "\n",
            "### Input:\n",
            "rumpai atsakyk skaičiais.\n",
            "\n",
            "### Response:\n",
            "Saulės sistemoje yra 8 planetų.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EVALUATION:**"
      ],
      "metadata": {
        "id": "bYn-hK_S0gXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n"
      ],
      "metadata": {
        "id": "Bs5vfveV6a9X"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Reference Text from chat gpt\n",
        "reference = \"University of New Haven's students are proudly known as Chargers, embodying the spirit of drive and determination in everything they do. With a strong sense of community and pride, Chargers are known for their academic excellence, innovative thinking, and commitment to making a positive impact. Represented by their spirited mascot, the horse, they charge forward with unparalleled energy, whether it's in academics, athletics, or community service. At the University of New Haven, students not only strive for success but also inspire those around them to achieve greatness, making the Charger legacy truly remarkable!\"\n",
        "\n",
        "hypothesis = response_1  # Generated response from the model\n",
        "\n",
        "# Load pre-trained model for semantic similarity\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Compute embeddings\n",
        "embeddings = model.encode([reference, hypothesis])\n",
        "\n",
        "# Calculate cosine similarity\n",
        "similarity = util.cos_sim(embeddings[0], embeddings[1])\n",
        "\n",
        "print(f\"Semantic Similarity: {similarity.item():.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKOdXGrP2EN7",
        "outputId": "29cafd8d-d893-4c2a-f6bd-e8b9df493bab"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic Similarity: 0.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Reference Text from chat gpt\n",
        "reference = \"Saulės sistemoje yra aštuonios.\"\n",
        "\n",
        "hypothesis = response_2  # Generated response from the model\n",
        "\n",
        "# Load pre-trained model for semantic similarity\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Compute embeddings\n",
        "embeddings = model.encode([reference, hypothesis])\n",
        "\n",
        "# Calculate cosine similarity\n",
        "similarity = util.cos_sim(embeddings[0], embeddings[1])\n",
        "\n",
        "print(f\"Semantic Similarity: {similarity.item():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKiCOG6i5gck",
        "outputId": "7edddf6c-632a-443d-ce8e-941698a222fd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic Similarity: 0.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1**"
      ],
      "metadata": {
        "id": "Oko6iew51o-t"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c83d243e4d2488989aa7c7994f466b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d51e36680ee449b88e3fa28a06a8b451",
              "IPY_MODEL_b4a7fa890ef84508b6a2034d0ec8d97d",
              "IPY_MODEL_7d7e4105d01547dab146fc2ec34d4cbb"
            ],
            "layout": "IPY_MODEL_cbee8c3ee84c497f82886b443fa24907"
          }
        },
        "d51e36680ee449b88e3fa28a06a8b451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_181012a5b5f6465a80537f6c1b3a6c25",
            "placeholder": "​",
            "style": "IPY_MODEL_03ad7a12b09845afb6a844864213d7f4",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b4a7fa890ef84508b6a2034d0ec8d97d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a03fe2db19a34fc3a47092af4e9b9096",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be40648fcff241a7afb509470b5037cc",
            "value": 3
          }
        },
        "7d7e4105d01547dab146fc2ec34d4cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_233ba5f201684bd1afcd48b96ffcbd0e",
            "placeholder": "​",
            "style": "IPY_MODEL_2990151a212141cba52aecddb9eb54a2",
            "value": " 3/3 [00:12&lt;00:00,  3.87s/it]"
          }
        },
        "cbee8c3ee84c497f82886b443fa24907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "181012a5b5f6465a80537f6c1b3a6c25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03ad7a12b09845afb6a844864213d7f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a03fe2db19a34fc3a47092af4e9b9096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be40648fcff241a7afb509470b5037cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "233ba5f201684bd1afcd48b96ffcbd0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2990151a212141cba52aecddb9eb54a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}